{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# Useful starting lines\r\n",
    "%matplotlib inline\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%load_ext autoreload\r\n",
    "%autoreload 2\r\n",
    "\r\n",
    "# Loading and standardizing the training data\r\n",
    "from proj1_helpers import *\r\n",
    "from implementations import *\r\n",
    "y, tX, ids = load_csv_data('data/train.csv')\r\n",
    "tX = standardize(tX)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# Splitting dataset into train and validation sets\r\n",
    "ratio = 0.8  # Ratio of samples to use in new train set\r\n",
    "np.random.seed(0)  # Fixing a seed for reproducibility\r\n",
    "rand_ind = np.random.permutation(np.arange(len(y)))\r\n",
    "\r\n",
    "y_train, y_valid = y[int(ratio*len(y)):], y[:int(ratio*len(y))]\r\n",
    "tX_train, tX_valid = tX[int(ratio*len(y)):], tX[:int(ratio*len(y))]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Function for calculating the F1-score for a fit"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "def f1_score(y_valid, tX_valid, weights):\r\n",
    "    \"\"\"\r\n",
    "    Return the F1-score achieved with the predictions of a validation set\r\n",
    "    \r\n",
    "    Parameters\r\n",
    "    ----------\r\n",
    "    y_valid : np.ndarray\r\n",
    "        Vector with the validation labels.\r\n",
    "    tX_valid : np.ndarray\r\n",
    "        Array with the validation samples as rows and the features as columns.\r\n",
    "    weights : np.ndarray\r\n",
    "        Vector containing the weights.\r\n",
    "\r\n",
    "    Returns\r\n",
    "    -------\r\n",
    "    f1 : float\r\n",
    "        F1-score for this configuration (the closer to 1 the better)\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    # Obtaining the predictions\r\n",
    "    y_pred = predict_labels(weights, tX_valid)\r\n",
    "\r\n",
    "    # Calculating number of true positives, false positives, and false negatives\r\n",
    "    num_tp = np.sum(y_pred == y_valid)\r\n",
    "    num_fp = np.sum((y_pred == 1) & (y_valid == -1))\r\n",
    "    num_fn = np.sum((y_pred == -1) & (y_valid == 1))\r\n",
    "\r\n",
    "    precision = num_tp / (num_tp + num_fp)\r\n",
    "    recall = num_tp / (num_tp + num_fn)\r\n",
    "\r\n",
    "    f1 = 2 * precision * recall / (precision + recall)\r\n",
    "    \r\n",
    "    return f1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regressors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Least squares gradient descent"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "# Hyperparameters\r\n",
    "initial_w = np.ones(tX_train.shape[1], dtype=float)\r\n",
    "max_iters = 100\r\n",
    "gamma = 0.1\r\n",
    "\r\n",
    "# Fitting\r\n",
    "weights, loss = least_squares_GD(y_train, tX_train, initial_w, max_iters, gamma)\r\n",
    "\r\n",
    "# Scoring\r\n",
    "f1 = f1_score(y_valid, tX_valid, weights)\r\n",
    "print(\"F1-score achieved with 'least_squares_GD': F1 = \", f1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F1-score achieved with 'least_squares_GD': F1 =  0.8285734367312514\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    " ## Least squares stochastic gradient descent"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "# Hyperparameters\r\n",
    "initial_w = np.ones(tX_train.shape[1], dtype=float)\r\n",
    "max_iters = 1000\r\n",
    "gamma = 0.01\r\n",
    "\r\n",
    "# Fitting\r\n",
    "weights, loss = least_squares_SGD(y_train, tX_train, initial_w, max_iters, gamma)\r\n",
    "\r\n",
    "# Scoring\r\n",
    "f1 = f1_score(y_valid, tX_valid, weights)\r\n",
    "print(\"F1-score achieved with 'least_squares_SGD': F1 = \", f1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F1-score achieved with 'least_squares_SGD': F1 =  0.816119713974523\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Least squares (normal equation)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "# Fitting\r\n",
    "weights, loss = least_squares(y_train, tX_train)\r\n",
    "\r\n",
    "# Scoring\r\n",
    "f1 = f1_score(y_valid, tX_valid, weights)\r\n",
    "print(\"F1-score achieved with 'least_squares': F1 = \", f1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F1-score achieved with 'least_squares': F1 =  0.8352861701879847\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ridge regression (for least squares normal equation)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "# Hyperparameters\r\n",
    "lambda_ = 10\r\n",
    "\r\n",
    "# Fitting\r\n",
    "weights, loss = ridge_regression(y_valid, tX_valid, lambda_)\r\n",
    "\r\n",
    "# Scoring\r\n",
    "f1 = f1_score(y_valid, tX_valid, weights)\r\n",
    "print(\"F1-score achieved with 'ridge_regression': F1 = \", f1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F1-score achieved with 'ridge_regression': F1 =  0.8347297155575235\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Logistic regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "# Hyperparameters\r\n",
    "initial_w = np.ones(tX_train.shape[1], dtype=float)\r\n",
    "max_iters = 100\r\n",
    "gamma = 0.1\r\n",
    "\r\n",
    "# Fitting\r\n",
    "# weights, loss = logistic_regression(y, tX, initial_w, max_iters, gamma)\r\n",
    "\r\n",
    "# Scoring\r\n",
    "f1 = f1_score(y_valid, tX_valid, weights)\r\n",
    "print(\"F1-score achieved with 'logistic_regression': F1 = \", f1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regularized logistic regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# Hyperparameters\r\n",
    "lambda_ = 0.1\r\n",
    "initial_w = np.ones(tX_train.shape[1], dtype=float)\r\n",
    "max_iters = 100\r\n",
    "gamma = 0.1\r\n",
    "\r\n",
    "# Fitting\r\n",
    "# weights, loss = reg_logistic_regression(y, tX, lambda_, initial_w, max_iters, gamma)\r\n",
    "\r\n",
    "# Scoring\r\n",
    "f1 = f1_score(y_valid, tX_valid, weights)\r\n",
    "print(\"F1-score achieved with 'reg_logistic_regression': F1 = \", f1)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "fb487646d2ff43bdda56d3757f53914077f9958e378e2f12b27b72e0e80564a5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}