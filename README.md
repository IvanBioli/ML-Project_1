# ML project 1 - Higgs Boson
We implement six standard versions and one optimized version of a linear egressor. Subsequently, the Higgs boson data set for binary classification from 30 numerical features is used for testing our implementations. We perform various preprocessing techniques and tune the parameters of our regressors to maximize in first priority the F1-score and in second priority the accuracy of the predictions.

The features in the data set record numerical measurements that coincide with the observation of either a decay signature that was caused by an event involving a Higgs boson ('s' for signal) or one that is not related to Higgs boson like decays ('b' for background). Based on 250'000 samples of training data, our goal is to predict the unknown labels for the test data.

[![Status](https://img.shields.io/badge/status-active-success.svg)]()


## ğŸ“ Table of Contents
- [â›ï¸ Minimal working example](#ï¸-minimal-working-example)
- [ğŸ” Reproduce results](#ï¸-reproduce-results)
- [ğŸ“‚ File structure](#ï¸-file-structure)
- [ğŸ“š References](#ï¸-references)
- [âœï¸ Authors](#ï¸-authors)

## â›ï¸ Minimal working example
Open your terminal, and use the command `git clone https://github.com/FMatti/ML_project1` to clone a copy of our repository on your machine. For a minimal working example of our implementations, open a new python file, and execute the following program:

    from proj1_helpers import *
    from implementations import *
    y_train, tX_train, _ = load_csv_data('data/train.csv')
    tX_train = standardize(tX_train)
    print(least_squares_GD(y_train, tX_train))
    print(least_squares_SGD(y_train, tX_train))
    print(least_squares(y_train, tX_train))
    print(ridge_regression(y_train, tX_train))
    print(logistic_regression(y_train, tX_train))
    print(reg_logistic_regression(y_train, tX_train))

## ğŸ” Reproduce results
To reproduce the results we have shown in Table 2 of our report, please navigate into this repository, download the [train.csv](https://github.com/epfml/ML_course/blob/master/projects/project1/data/train.csv.zip) and [test.csv](https://github.com/epfml/ML_course/blob/master/projects/project1/data/test.csv.zip) files and place them in a folder called `data`, and execute the run.py script with the following command: `python run.py`. The predictions for each of the regressor configurations used will be stored in the folder `data/submission_[NAME OF THE REGRESSOR]`.


## ğŸ“‚ File structure

```
ML_project1 
â”‚   README.md               (The file you are reading right now)
â”‚   proj1_helpers.py        (Support functions that are provided by the lecturers)
|   project1.ipynb          (Central notebook where one can execute the whole pipeline (preprocessing, regressors, scores) and see visualizations of the data set)
â”‚   implementations.py      (Contains all the implemented regressors)
â”‚   run.py                  (To be executed to get the results) 
â”‚
â””â”€â”€â”€data
â”‚   â”‚   test.csv	        (Test data)
â”‚   â”‚   train.csv           (Training data)
â”‚   
â””â”€â”€â”€report
    â”‚   main.tex            (Main typesetting file)
    â”‚   style.sty           (Stylesheet)
    |   biblio.bib          (Bibliography file)
```

## ğŸ“š References
[1] Adam-Bourdariosa C., Cowanb G., Germain C.,I. Guyond B. KÃ©gl, Rousseau D.Learning to discover: [The Higgs boson machine learning challenge](https://higgsml.lal.in2p3.fr/files/2014/04/documentation_v1.8.pdf). 2014. 

[2] Jaggi M., Urbanke R., Khan M. E.Machine Learning (CS-433): [Lecture notes](https://github.com/epfml/ML_course). 2021.

## âœï¸ Authors
- Fabio Matti
- Ivan Bioli
- Olivier Staehli
